{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1gP8yVFattHocYzUvqFW3lyrcrSMaVHtu",
      "authorship_tag": "ABX9TyOHodYpNqYGv+Bzwnl2wDca",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roshni19sharma99/LLM/blob/main/Stemminga_and_Lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming\n",
        "It is a process of reducing the word to its stem by exclusing the prefixes, suffixes to the root of words known as lemma\n",
        "\n",
        "this process is faster than lammatization but provides less accuracy\n",
        "applications - spam mail  classification, sentiment analysis"
      ],
      "metadata": {
        "id": "vCQRrk8MKo-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PorterStemmer**\n",
        "\n",
        "This stemmer is known for its speed and simplicity. The main applications of Porter Stemmer include data mining and Information retrieval. However, its applications are only limited to English words. Also, the group of stems is mapped on to the same stem and the output stem is not necessarily a meaningful word. The algorithms are fairly lengthy in nature and are known to be the oldest stemmer."
      ],
      "metadata": {
        "id": "PGbfhqTWq2ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "yuH74UQLm9bV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eating\",\"eaten\",\"eats\",\"history\",\"finally\",\"finalized\"]"
      ],
      "metadata": {
        "id": "8qdLDD0Vnmzr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemming = PorterStemmer()"
      ],
      "metadata": {
        "id": "8eXxrRofn2bh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(word+\"---->\"+stemming.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HOOKC5yn6mF",
        "outputId": "32d7f72d-88f7-489e-d078-81fcda7be632"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating---->eat\n",
            "eaten---->eaten\n",
            "eats---->eat\n",
            "history---->histori\n",
            "finally---->final\n",
            "finalized---->final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# **RegexpStemmer**\n",
        "- A stemmer that uses regular expressions to identify\n",
        "morphological affixes. Any substrings that match the regular expressions will be removed.\n",
        "The Regexp Stemmer, or Regular Expression Stemmer, is a stemming algorithm that utilizes regular expressions to identify and remove **suffixes** from words. It allows users to define custom rules for stemming by specifying patterns to match and remove."
      ],
      "metadata": {
        "id": "2TdCFtZiongM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer"
      ],
      "metadata": {
        "id": "WLK_XgSEpYRA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer = RegexpStemmer('ing$|s$|able$|ally$|lized$',min=4)"
      ],
      "metadata": {
        "id": "sgbL30fyph59"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(word + \"--->\" + reg_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHo3hi81rzDC",
        "outputId": "66c428d9-ccbb-481b-f162-d600d440e816"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating--->eat\n",
            "eaten--->eaten\n",
            "eats--->eat\n",
            "history--->history\n",
            "finally--->fin\n",
            "finalized--->fina\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Snowball Stemmer**\n",
        "The Snowball Stemmer, compared to the Porter Stemmer, is multi-lingual as it can handle non-English words. It supports various languages and is based on the ‘Snowball’ programming language, known for efficient processing of small strings.\n",
        "\n",
        "Snowball stemmer is slightly better that porter stemmer as it works better on few words."
      ],
      "metadata": {
        "id": "B5GKIdaqUTMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer"
      ],
      "metadata": {
        "id": "fXsHbIw6UYyu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snowball_var = SnowballStemmer('english')"
      ],
      "metadata": {
        "id": "EhsmD7YQUgxh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(word + \"--->\" + snowball_var.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95rW628QVK92",
        "outputId": "38ad6205-0987-4664-9413-cd89d68f022b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating--->eat\n",
            "eaten--->eaten\n",
            "eats--->eat\n",
            "history--->histori\n",
            "finally--->final\n",
            "finalized--->final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snowball_var.stem('fairly'), snowball_var.stem('sportingly')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG4cQ1Z2Vf-R",
        "outputId": "d04a4ecc-bc12-42f6-cdb4-f12b82bd95d3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fair', 'sport')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}